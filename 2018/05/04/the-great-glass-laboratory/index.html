<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.30.2" />


<title>The Great Glass Laboratory - Let&#39;s See What Happens When We Take Away The Puppy</title>
<meta property="og:title" content="The Great Glass Laboratory - Let&#39;s See What Happens When We Take Away The Puppy">



  







<link rel="stylesheet" href="/oliverclark.github.io/css/fonts.css" media="all">
<link rel="stylesheet" href="/oliverclark.github.io/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/oliverclark.github.io/" class="nav-logo">
    <img src="/oliverclark.github.io/images/puppa.JPG"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/oliverclark.github.io/about/">About</a></li>
    
    <li><a href="https://github.com/olijimbo">GitHub</a></li>
    
    <li><a href="https://osf.io/rza9u/">OSF</a></li>
    
    <li><a href="https://twitter.com/PsyTechOli">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">14 min read</span>
    

    <h1 class="article-title">The Great Glass Laboratory</h1>

    
    <span class="article-date">2018/05/04</span>
    

    <div class="article-content">
      <div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Hi - this is a companion blog to the talk I gave on knitting open science into my PhD Project. It is, in effect, a list of resources that I use and plan to use in my own research and very much see it as part of my post graduate training.</p>
<p>I am a second year PhD student currently, but I came into this late in the day. I originally left academia in 2010 and worked in a bookshop for 5 years before becoming a technical officer for the MMU psychology department where I eventually landed funding to do a full time PhD project on the psychology of videogame avatars and exercise.</p>
<p>Whilst I was away from academia, it seems that Psychology as a science took a swing at physics and ended up clouting itself. I wont go into details about the background because it has been covered very well <a href="https://replicationindex.wordpress.com/category/bem/">elsewhere</a></p>
<div class="figure">
<img src="Methods_Slides/uppercut.gif" />

</div>
<div id="section" class="section level3">
<h3></h3>
<p>So when I returned to the field, it turned out that a lot of the methods I used to employ were now turning out to be very bad for science in general.</p>
</div>
</div>
<div id="bad" class="section level2">
<h2>Bad?</h2>
<p>The figure below is taken from Marcus Munafò and colleagues “A Manifesto for Reproducible Science”, a seminal paper that highlights many of the causes of replicability issues in psychology, including pretending that exploratory findings are confirmatory (Hypothesizing after the results are known) and P-Hacking which is a set of techniques used to reduce the p-value of a study below the 0.05 alpha threshold.</p>
<div class="figure">
<img src="Methods_Slides/Slide13.png" />

</div>
<p><span class="citation">(Munafò et al. 2017)</span></p>
<p><span class="citation">J. P. Simmons, Nelson, and Simonsohn (2011)</span> used many of these p-hacking techniques to ‘experimentally demonstrate’ that when participants listen to “When I’m 64” by the Beatles they actually got younger. The point here is that the researchers knowlingly used the same techniques that are often used in psychology to demonstrate something that is literally impossible, so which does not help our confidence in these methods when there is a lot of uncertainty surrounding an effect. I’d highly recommend reading this paper.</p>
<p>Open Science advocates are often accused of being dogmatic and thuggish in their approaches to what may be deemed ‘questionable research practices’. I’m going to avoid this, but I will highlight one study that could use a bit of a roasting:</p>
</div>
<div id="roasting" class="section level2">
<h2>Roasting!</h2>
<div class="figure">
<img src="Methods_Slides/Slide09.png" />

</div>
<p>As you can see from the above abstract - the separate response stimuli were separated into separate analyses, and terms like ‘trended to significance’ are used. This study is clearly:</p>
<div class="figure">
<img src="Methods_Slides/Slide10.png" />

</div>
<p>The author was so impressed with the results that they even missed the typo on the first line!</p>
<p><strong>That author was me</strong>. The abstract is from one of my three Masters dissertations from 2008, and this is why I felt it was very important for me to follow good practices in my current studies.</p>
</div>
<div id="aim" class="section level2">
<h2>Aim</h2>
<p>So my aim is to make my research outputs more informative, and usable to future researchers. I want my studies to be adequately powered, for the analyses to be reproducible and for the materials to be available as far as possible (I am using games consoles and VR so this is a work in progress).</p>
</div>
<div id="how" class="section level2">
<h2>How</h2>
<p>I intend to do this by following the guidance from <span class="citation">Munafò et al. (2017)</span> and Chris Chambers’ excellent book The 7 Deadly Sins of Psychology <span class="citation">(C. Chambers 2017)</span>, and by ensuring that I am considering transparency and reproducibility at every step of my studies.</p>
</div>
<div id="project" class="section level2">
<h2>Project</h2>
<p>The diagram below shows what I would expect a typical PhD trajectory to look like. It has an exploratory phase, a confirmatory phase and a synthesis phase (RCT) in which what is known and what has been found out is used to create a product or intervention.</p>
<div class="figure">
<img src="Methods_Slides/Slide01.png" />

</div>
</div>
<div id="meta-project" class="section level2">
<h2>Meta-Project</h2>
<p>By using various tools and procedures, I can map open, transparent and reproducible practices onto each phase, as shown in the incredibly noisy figure below. This is the meta-project:</p>
<div class="figure">
<img src="Methods_Slides/Slide02.png" />

</div>
<p>Which stands up nicely on its own:</p>
<div class="figure">
<img src="Methods_Slides/Slide03.png" />

</div>
<p>And can be clustered into three themes: Critical, Prescient, and Open.</p>
<div class="figure">
<img src="Methods_Slides/Slide05.png" />

</div>
</div>
<div id="be-critical" class="section level1">
<h1>Be Critical</h1>
<p>We are often told during our studies that we need to think about studies critically. To look at a theory and take opposing arguments into consideration and synthesis an opinion from what is known. However, this angle assumes that the papers that you are reading are accurate.</p>
<p>We know that there is a file drawer problem whereby only alpha&lt;0.05 studies are generally published, and that QRPs occur <span class="citation">(John, Loewenstein, and Prelec 2012)</span> so we need to be critical on this level too.</p>
<p>A number of tools can be used to ensure that your work is based upon solid foundations and these are listed below. It is important that your work is not based upon unreplicatable, p-hacked or just wrong results, because your work may suffer as a result!</p>
<ul>
<li><p><a href="http://statcheck.io">Statcheck</a> <span class="citation">(Epskamp and Nuijten 2015)</span></p></li>
<li><p><a href="http://www.p-curve.com">P-Curve</a> <span class="citation">(Simonsohn, Nelson, and Simmons 2014)</span></p></li>
</ul>
<p>Statcheck is a spell checker for statistics. It extracts APA format statistics from papers and recalculates the p-values based on the degrees of freedom and test statistics. You can go to the website and upload papers to it or use it as an R Package.</p>
<p>P-Curve compares the distribution of effect sizes that are observed in a set of studies with the expected distribution of effect sizes if there is an effect. In the latter case there should be right skew (i.e. far more p values below 0.01). In effects where there may be a file drawer issue, or p-hacked studies, there will be more p-values around the 0.05 region. P-Curve also estimates how likely it is that an effect will replicate which has been useful in my own studies.</p>
<div id="be-self-critical" class="section level2">
<h2>Be Self Critical</h2>
<p>These tools can be used to check my own work for inconsistencies. Use it after you spell check your work!</p>
</div>
</div>
<div id="be-prescient" class="section level1">
<h1>Be Prescient</h1>
<p>By this I mean know exactly what you are going to do before you do it to avoid harking and flexible analysis methods.</p>
<p>I saw this as a play on words of sorts:</p>
<div id="be-a-pre-registering-scientist" class="section level2">
<h2>Be a Pre<em>-registering</em> scient<em>ist</em></h2>
<p>This can be done using a number of platforms, such as osf.io and aspredicted.org.</p>
<ul>
<li><a href="https://aspredicted.org">Pre-registration</a></li>
<li><a href="https://osf.io/8mpji/">Registered Reports</a></li>
<li><a href="http://prisma-statement.org">PRISMA/MARS</a> <span class="citation">(Moher et al. 2015)</span></li>
</ul>
<p>You can also try and guarantee yourself a publication by submitting your PhD study ideas to a journal that accepts Registered Reports. By doing this, you will get feedback from experts in the area which will enhance the quality of the overall study. Once you have got through stage one review, you get an In Principal Acceptance and your paper will almost certainly be published regardless of the results.</p>
<p>The final entry above is a special case of pre-registration for meta-analyses and systematic reviews. Very few psychological MA/SRs follow reporting guidelines and I found it to be a very useful exercise to complete. You fill out all of the outcomes, comparators, interventions, analysis plans, exclusion criteria etc before your run your searches and freeze the plan in a repository such as PROSPERO. It means that your whole process can easily be followed by other researchers, and it makes you consider risk of bias within studies and control for quality.</p>
</div>
</div>
<div id="be-open" class="section level1">
<h1>Be Open</h1>
<p>Finally, I wanted to make my research as transparent as possible. To do this I use open source software as much as possible and ensure that anything I make can be run on most platforms. For 3D/VR stuff I use Unity which can compile onto everything, and I also use a lot of Python based software like Blender.</p>
<p>For analysis I am an R convert. I think learning to code was one of the best things I could have done over the last few years and I recommend it to anyone who is involved in data processing (which we are!)</p>
<ol style="list-style-type: decimal">
<li>Research Tools</li>
</ol>
<ul>
<li><a href="https://cran.r-project.org/mirrors.html">R</a></li>
<li><a href="https://www.rstudio.com/products/rstudio/download/">RStudio</a></li>
<li><a href="https://jasp-stats.org">JASP</a></li>
<li><a href="https://www.jamovi.org">JAMOVI</a></li>
<li><a href="http://www.psychopy.org">PsychoPy</a></li>
<li><a href="http://rqda.r-forge.r-project.org">RQDA</a></li>
<li><a href="https://formr.org">FormR</a></li>
</ul>
<p>For those who don’t want to code, JASP and JAMOVI have graphical user interfaces a bit like SPSS but they are built on an R back-end. JASP focuses on Bayesian statistical methods and JAMOVI can export all of your GUI analyses to R scripts which is a very powerful function!</p>
<p>I mentioned RQDA above for qualitative analysis. I have yet to try it properly because it is very hard to install at the moment and I can only get it working on a VirtualBox machine running the very latest version of Ubuntu. That being said, it is great that there is an R based Qualitative analysis program and I look forward to using it later.</p>
<p>FormR is a survey design platform and is much like a very flexible version of qualtrics but with the whole of the R programming language at your disposal rather than a few segments of JavaScript!</p>
<ol start="2" style="list-style-type: decimal">
<li>Repositories</li>
</ol>
<ul>
<li><a href="https://osf.io">Open Science Framework</a></li>
<li><a href="https://github.com">GitHub</a></li>
<li><a href="https://psyarxiv.com">Pre-prints</a></li>
</ul>
<p>Consider sharing your data, software and analysis as well as finished papers on the above repositories. I keep all of my Psychopy programs on OSF and I recently found out that someone in Iceland was using one of them for an EEG project which was awesome. I intend to upload my thesis chapters to PsyArxiv as I write them. This will allow others to read them and offer comments for publications or use my literature reviews etc.</p>
<div id="disclosure-statements" class="section level2">
<h2>Disclosure Statements</h2>
<p>A radical method of openness for people who have already published data is releasing post hoc disclosure statements to indicate the degree to which QRPs were used in these studies. This is an excellent idea and aims to make “the past more useful”. <a href="https://rmwillen.info/publications/">Rebecca Willén</a> did this for her entire PhD thesis which included a number of published articles. This is discussed in a podcast episode recommended below.</p>
</div>
</div>
<div id="be-proactive" class="section level1">
<h1>Be Proactive</h1>
<p>Changing your workflows and adopting new techniques is a lot of work and as a PhD student it is unlikely that you will be taught these things. So if you don’t already know them, you will have to be proactive and teach yourself or attend workshops. The benefits of doing this are enormous though. Below are some recommended resources.</p>
</div>
<div id="stats-and-open-practices" class="section level1">
<h1>Stats and Open Practices</h1>
<p>I cannot recommend Daniel Lakens’ MOOC course enough. It basically covers everything I have just mentioned and more. From Theory building to pre-registration to analysis, Daniel takes you through the research process from start to finish and offers a number of different methods to approach your analysis including equivalence testing, likelihoods and Bayesian methods.</p>
<ul>
<li>Improve your statistical inferences</li>
<li><a href="https://www.coursera.org/learn/statistical-inferences">Daniel Lakens’ free MOOC</a></li>
</ul>
</div>
<div id="learn-to-code" class="section level1">
<h1>Learn to code</h1>
<p>I get very angry about this. When I was at 6th form I kept asking school teachers to include programming in ICT classes but the curriculum was set and we had to make takeaway menus using PowerPoint! Fortunately there are so many resources available now that learning is quite straightforward. The <a href="https://software-carpentry.org">Software Carpentry</a> courses are really good.</p>
</div>
<div id="engage" class="section level1">
<h1>Engage</h1>
<p>It is possible that your supervisors will not approve of open science practices. I was very lucky in that all three of my supervisors have been very supportive and have even adopted pre-registration themselves. However there is a lot of negativity about the movement. Try and find people in your own labs and departments who share your values and arrange meetings and workshops. That is what I am doing with Tom Hostler from MMU.</p>
</div>
<div id="keep-up-to-date-with-developments" class="section level1">
<h1>Keep up to date with developments:</h1>
<p>Since it is such a new reformation, issues surrounding replication and good scientific practice are changing very quickly. A good example is the debate between changing the alpha threshold to 0.005 and justifying your alpha. Podcast are a great way to keep up to date, as well as Twitter.</p>
</div>
<div id="podcasts" class="section level1">
<h1>Podcasts</h1>
<p>There is a great quote regarding audio-books from Stephen King’s book On Writing:</p>
<blockquote>
<p>“<em>As for all the wonderful radio you will be missing, come on — how many times can you listen to Deep Purple sing ‘Highway Star’?</em>”</p>
</blockquote>
<p><span class="citation">(King 2002)</span></p>
<p>When I read this a switched to audio-books<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> and then to podcasts when travelling or running or doing the washing. They can be very entertaining and uplifting.</p>
<p>Two of my favorites are:</p>
<ul>
<li><a href="https://soundcloud.com/everything-hertz">Everything Hertz</a> - irreverent science talk and bantz</li>
<li>[Black Goat Podcast] (<a href="http://www.theblackgoatpodcast.com" class="uri">http://www.theblackgoatpodcast.com</a>) - Great advice for ECRs and people interested in reproducibility</li>
</ul>
<div class="figure">
<img src="Methods_Slides/Slide11.png" />

</div>
<p>I started listening to Everything Hertz first and I would say that it solidified my interest in the OS movement - particularly the episodes with <a href="https://soundcloud.com/everything-hertz/44-whos-afraid-of-the-new-bad-people-with-nick-brown">Nick Brown</a>, <a href="https://soundcloud.com/everything-hertz/47-truth-bombs-from-a-methodological-freedom-fighter-with-anne-scheel">Anne Scheel</a>, <a href="https://soundcloud.com/everything-hertz/43-death-taxes-and-publication-bias-in-meta-analysis-with-daniel-lakens">Daniel Lakens</a> and <a href="https://soundcloud.com/everything-hertz/57-radical-transparency-with-rebecca-willen">Rebecca Willén</a>.</p>
<p>The Black Goat have weekly letters from ECRs and cover issues surrounding the replicability crisis as well as providing advice and dealing with the struggles of academia such as work-life balance and <a href="https://blackgoat.podbean.com/e/episode-3-no-youre-the-impostor/">imposter syndrome</a>.</p>
</div>
<div id="meet-like-minded-people" class="section level1">
<h1>Meet Like-minded People</h1>
<p>Off the back of the podcasts I joined SIPS and will be attending their meeting in Grand Rapids this June. So far it has been a very welcoming society and they do everything possible to ensure inclusion and representation at all levels and groups.</p>
<ul>
<li><a href="www.improvingpsych.org">SIPS</a></li>
</ul>
<div class="figure">
<img src="Methods_Slides/Slide12.png" />

</div>
<p>Also, push for open science symposia at every conference - I can’t remember whose idea this was<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>, but I think I heard it at the</p>
</div>
<div id="bbsrc-reproducibility-retreat" class="section level1">
<h1>BBSRC Reproducibility Retreat</h1>
<p>I was lucky enough to land <a href="http://www.bris.ac.uk/expsych/events/reproducibility2018/">a place on this</a> in April and it was amazing. I understand that they have one funding for one more year so if you can make it to the retreat, I would highly recommend it.</p>
<p>It was a 5 day intensive workshop on advanced replicability and reproducibility methods in an Mansion in Windsor, led by experts and trail blazers in the field.</p>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<p>So I’m just going to end this with some of the benefits and perceived risks involved in adopting open practices.</p>
<div id="benefits" class="section level2">
<h2>Benefits</h2>
<div id="reusability" class="section level3">
<h3>Reusability</h3>
<p>A key benefit is the re-usability of everything you do. Whether it is manuscripts or code, you will always have access to it and there are opportunities for others to use, add to or improve your work. My major thesis from my MRes course only exists now in hard form in a cupboard at the University of Hull.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> This will not happen if you adopt an open workflow.</p>
<p>It also means you can use other researchers materials and data so you are not having to reinvent the wheel over again. Platforms like OpenFMRI are great for this.</p>
</div>
<div id="expert-advice" class="section level3">
<h3>Expert advice</h3>
<p>Getting feedback on registered reports and pre-registrations from experts in the field will help make your studies more robust and more valuable in general. I received some feedback from a reviewer on my Meta-analysis pre-registration and it was very useful. The same goes for pre-prints - someone (other than your supervisor) might be able to offer some advice on exploratory analyses or check your interpretations of the results.</p>
</div>
<div id="not-fooling-yourself" class="section level3">
<h3>Not fooling yourself</h3>
<p>It is easy to let the cognitive biases take over when you are doing your own research. I was a sucker for this in my earlier years. Being transparent and accountable via pre-registration can reassure you that you are in fact supporting your hypothesis and are not doing the mental gymnastics involved in fitting your hypothesis to your data.</p>
</div>
</div>
<div id="misconceptions" class="section level2">
<h2>Misconceptions</h2>
<div id="pre-registration-stifles-exploration" class="section level3">
<h3>Pre-registration stifles exploration</h3>
<p>This is not the case - HARKing does the stifling. All Pre-registration does is distinguishes between confirmatory and exploratory hypotheses. You can report any interesting findings and then replicate them instead of having to change your who introduction and research question to fit the asterisks!</p>
</div>
<div id="youll-get-scooped." class="section level3">
<h3>You’ll get Scooped.</h3>
<p>There is a fear that another nefarious lab will get hold of your registration and run the study before you can. This does happen in non-pre-registered studies, but in those there is no read-only frozen file that says it was your idea first! Also, in registered reports the registrations are generally kept private until stage 2.</p>
<p>I hope this has been useful for some people!</p>
</div>
</div>
</div>
<div id="thank-you-for-listening-reading" class="section level1">
<h1>Thank you for <del>listening</del> reading</h1>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-chambers2017seven">
<p>Chambers, Chris. 2017. <em>The Seven Deadly Sins of Psychology: A Manifesto for Reforming the Culture of Scientific Practice</em>. Princeton University Press.</p>
</div>
<div id="ref-Epskamp:2015aa">
<p>Epskamp, S, and MB Nuijten. 2015. “Statcheck: Extract Statistics from Articles and Recompute P Values (R Package Version 1.0. 1.).”</p>
</div>
<div id="ref-John:2012aa">
<p>John, Leslie K., George Loewenstein, and Drazen Prelec. 2012. “Measuring the Prevalence of Questionable Research Practices with Incentives for Truth Telling.” <em>Psychological Science</em> 23 (5). SAGE Publications Inc: 524–32. doi:<a href="https://doi.org/10.1177/0956797611430953">10.1177/0956797611430953</a>.</p>
</div>
<div id="ref-king2002writing">
<p>King, Stephen. 2002. <em>On Writing</em>. Simon; Schuster.</p>
</div>
<div id="ref-moher2015preferred">
<p>Moher, David, Larissa Shamseer, Mike Clarke, Davina Ghersi, Alessandro Liberati, Mark Petticrew, Paul Shekelle, and Lesley A Stewart. 2015. “Preferred Reporting Items for Systematic Review and Meta-Analysis Protocols (Prisma-P) 2015 Statement.” <em>Systematic Reviews</em> 4 (1). BioMed Central: 1.</p>
</div>
<div id="ref-Munafo:2017aa">
<p>Munafò, Marcus R., Brian A. Nosek, Dorothy V. M. Bishop, Katherine S. Button, Christopher D. Chambers, Nathalie Percie du Sert, Uri Simonsohn, Eric-Jan Wagenmakers, Jennifer J. Ware, and John P. A. Ioannidis. 2017. “A Manifesto for Reproducible Science.” <em>Nature Human Behaviour</em> 1 (January). Macmillan Publishers Limited SN -: 0021 EP. <a href="http://dx.doi.org/10.1038/s41562-016-0021" class="uri">http://dx.doi.org/10.1038/s41562-016-0021</a>.</p>
</div>
<div id="ref-Simmons:2011aa">
<p>Simmons, Joseph P., Leif D. Nelson, and Uri Simonsohn. 2011. “False-Positive Psychology.” <em>Psychological Science</em> 22 (11). SAGE Publications Inc: 1359–66. doi:<a href="https://doi.org/10.1177/0956797611417632">10.1177/0956797611417632</a>.</p>
</div>
<div id="ref-simonsohn2014p">
<p>Simonsohn, Uri, Leif D Nelson, and Joseph P Simmons. 2014. “P-Curve: A Key to the File-Drawer.” <em>Journal of Experimental Psychology: General</em> 143 (2). American Psychological Association: 534.</p>
</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I am very impressionable<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Please let me know if it was your idea!<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>don’t go and read it, it’s not very good<a href="#fnref3">↩</a></p></li>
</ol>
</div>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-olijimbo-github-io-oliverclark-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/oliverclark.github.io/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/oliverclark.github.io/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    

    
  </body>
</html>

